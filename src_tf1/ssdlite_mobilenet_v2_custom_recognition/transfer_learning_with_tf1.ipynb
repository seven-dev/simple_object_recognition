{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following these:  \n",
    "https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html\n",
    "https://www.tensorflow.org/tutorials/load_data/tf_records#tfrecord_files_using_tfdata\n",
    "https://github.com/tensorflow/models/blob/master/research/object_detection/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import IPython.display as display\n",
    "import os\n",
    "import random\n",
    "\n",
    "print(tf.__version__)\n",
    "assert tf.__version__ == '1.13.1', 'This notebook was meant to be used with tensorflow v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../image_gathering/imgs\n"
     ]
    }
   ],
   "source": [
    "IMG_H, IMG_W = 160, 160\n",
    "ANNOTATIONS_PATH =  pathlib.Path('workspace/training_demo/annotations')\n",
    "IMAGES_PATH = '../../../image_gathering/imgs'\n",
    "data_root = pathlib.Path(IMAGES_PATH)\n",
    "print(data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "  image = tf.image.decode_jpeg(image, channels=3)\n",
    "  image = tf.image.resize(image, [IMG_H, IMG_W])\n",
    "  image /= 255.0  # normalize to [0,1] range\n",
    "  return image\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "  image = tf.io.read_file(path)\n",
    "  return preprocess_image(image)\n",
    "\n",
    "def load_and_preprocess_from_path_label(path, label):\n",
    "  return load_and_preprocess_image(path), label\n",
    "\n",
    "def load_training_images(data_root):\n",
    "    if not data_root.exists():\n",
    "        raise\n",
    "    # Images' paths\n",
    "    all_image_paths = list(data_root.glob('*/*'))\n",
    "    all_image_paths = [str(path) for path in all_image_paths]\n",
    "    random.shuffle(all_image_paths)\n",
    "    \n",
    "    # Labels\n",
    "    label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
    "    label_to_index = dict((name, index) for index,name in enumerate(label_names))\n",
    "    all_image_labels = [label_to_index[pathlib.Path(path).parent.name]\n",
    "                    for path in all_image_paths]\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((all_image_paths, all_image_labels))\n",
    "    image_label_ds = ds.map(load_and_preprocess_from_path_label)\n",
    "    \n",
    "    # Extra info\n",
    "    image_count = len(all_image_paths)\n",
    "    print(f'Number of images: {image_count}')\n",
    "    print(f'Label names: {label_names}')\n",
    "    return image_label_ds, label_names, image_count\n",
    "\n",
    "def dataset_split(ds, image_count, test=0.05, dev=0.05, train=0.9):\n",
    "    assert (test + dev + train == 1), 'test + dev + train should be equal to 1'\n",
    "    nt, nd = int(test*image_count), int(dev*image_count)\n",
    "    ntr = image_count - nt - nd\n",
    "    ds_test = ds.take(nt) \n",
    "    ds_dev = ds.skip(nt).take(nd) \n",
    "    ds_train = ds.skip(nt + nd).take(ntr)\n",
    "    return ds_test, ds_dev, ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 1056\n",
      "Label names: ['ethernet']\n"
     ]
    }
   ],
   "source": [
    "# Dataset of preprocessed images\n",
    "ds, labels, image_count = load_training_images(data_root)\n",
    "ds_test, ds_dev, ds_train = dataset_split(ds, image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def serialize_example(feature0, feature1):\n",
    "  \"\"\"\n",
    "  Creates a tf.Example message ready to be written to a file.\n",
    "  \"\"\"\n",
    "  # Create a dictionary mapping the feature name to the tf.Example-compatible\n",
    "  # data type.\n",
    "  feature = {\n",
    "      'feature0': _bytes_feature(tf.io.serialize_tensor(feature0).numpy()),\n",
    "      'feature1': _int64_feature(feature1)\n",
    "  }\n",
    "  \n",
    "  # Create a Features message using tf.train.Example.\n",
    "  example_proto = tf.train.Example(\n",
    "      features=tf.train.Features(\n",
    "          feature=feature))\n",
    "  return example_proto.SerializeToString()\n",
    "\n",
    "def tf_serialize_example(f0,f1):\n",
    "  tf_string = tf.py_function(\n",
    "    serialize_example, \n",
    "    (f0,f1),  # pass these args to the above function.\n",
    "    tf.string)      # the return type is <a href=\"../../api_docs/python/tf#string\"><code>tf.string</code></a>.\n",
    "  return tf.reshape(tf_string, ()) # The result is a scalar\n",
    "\n",
    "def store_dataset_as_tfrecord(filename, ds):\n",
    "    ds_serialized = ds.map(tf_serialize_example)\n",
    "    writer = tf.data.experimental.TFRecordWriter(filename)\n",
    "    writer.write(ds_serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_dataset_as_tfrecord(os.path.join(ANNOTATIONS_PATH, 'train.record'), ds_train)\n",
    "store_dataset_as_tfrecord(os.path.join(ANNOTATIONS_PATH, 'dev.record'), ds_dev)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data():\n",
    "    pass\n",
    "\n",
    "def convert_data_to_tfrecord():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1.         0.9882353  0.96862745]\n",
      "  [1.         0.9882353  0.96862745]\n",
      "  [1.         0.99215686 0.9529412 ]\n",
      "  ...\n",
      "  [0.7490196  0.69411767 0.6313726 ]\n",
      "  [0.7529412  0.69803923 0.63529414]\n",
      "  [0.76862746 0.6862745  0.6509804 ]]\n",
      "\n",
      " [[1.         0.9882353  0.96862745]\n",
      "  [1.         0.9882353  0.96862745]\n",
      "  [1.         0.99215686 0.9529412 ]\n",
      "  ...\n",
      "  [0.7921569  0.73333335 0.654902  ]\n",
      "  [0.77843136 0.7078431  0.6431373 ]\n",
      "  [0.7862745  0.7019608  0.66862744]]\n",
      "\n",
      " [[1.         1.         0.9137255 ]\n",
      "  [1.         1.         0.92156863]\n",
      "  [1.         1.         0.90588236]\n",
      "  ...\n",
      "  [0.89411765 0.8039216  0.68235296]\n",
      "  [0.8627451  0.78039217 0.68235296]\n",
      "  [0.8666667  0.76862746 0.7019608 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.5137255  0.49019608 0.47058824]\n",
      "  [0.5803922  0.54901963 0.5235294 ]\n",
      "  [0.6117647  0.57843137 0.5627451 ]\n",
      "  ...\n",
      "  [0.6431373  0.61960787 0.6117647 ]\n",
      "  [0.6019608  0.57843137 0.57843137]\n",
      "  [0.6627451  0.63529414 0.6431373 ]]\n",
      "\n",
      " [[0.6        0.5764706  0.5568628 ]\n",
      "  [0.59607846 0.5647059  0.5411765 ]\n",
      "  [0.6        0.5686275  0.5529412 ]\n",
      "  ...\n",
      "  [0.6392157  0.6117647  0.6117647 ]\n",
      "  [0.6745098  0.63529414 0.64705884]\n",
      "  [0.6392157  0.6117647  0.627451  ]]\n",
      "\n",
      " [[0.6        0.5764706  0.54901963]\n",
      "  [0.6019608  0.57058823 0.5470588 ]\n",
      "  [0.61960787 0.5882353  0.56078434]\n",
      "  ...\n",
      "  [0.65294117 0.62352943 0.6431373 ]\n",
      "  [0.63529414 0.60588235 0.62941176]\n",
      "  [0.66862744 0.6372549  0.67058825]]], shape=(160, 160, 3), dtype=float32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for f0,f1 in ds.take(1):\n",
    "  print(f0)\n",
    "  print(f1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
